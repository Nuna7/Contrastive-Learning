## ðŸ“Š Evaluation of SoM-LLava on Multi-View Images

### ðŸ“ Directory Structure

- **Evaluation root path**:  
  `/SoM/`

- **Input images**:  
  `/SoM/images/`

- **Output results**:  
  `/SoM/outputs/`

### ðŸ§  Models Used

#### ðŸ” Vision Models
- SemanticSAM (`semsam`)
- Segment Everything Everywhere All At Once (`seem`)

#### ðŸ’¬ Language Models
- **LLaVA 1.5 (13B)**  
  - Referred to as `huggingface` in output directory  
  - Trained specifically on the set of masks
- **LLaVA 1.6 (13B)**  
  - Referred to as `ollama` in output directory

> In `/SoM/outputs/`:
> - `huggingface/` â†’ Results from LLaVA 1.5 (13B)  
> - `ollama/` â†’ Results from LLaVA 1.6 (13B)  
> - `prompt1/` and `prompt2/` â†’ Represent different final outputs based on prompt variations

---

### ðŸ§ª Evaluation Code

- Evaluation code is located at:  
  `/SoM/set_off_mask_model/py`

---

### ðŸ“¦ Checkpoint Setup

1. Create a directory at:  
   `/SoM/checkpoints/`

2. Navigate to the script:  
   `/SoM/download_ckpt.sh`

3. Run the **first two commands** in the script to download checkpoints for:
   - `seem`
   - `semsam`
